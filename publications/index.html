<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Publications | Srinivasan Subramaniyan </title> <meta name="author" content="Srinivasan Subramaniyan"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://srinivasans74.github.io/publications/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Srinivasan</span> Subramaniyan </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blogs </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/Achievements/">teaching </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description"></p> </header> <article> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/seeb_gpu.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="seeb_gpu.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10.1145/3769102.3772715" class="col-sm-8"> <div class="title">SEEB-GPU: Early-Exit Aware Scheduling and Batching for Edge GPU Inference</div> <div class="author"> <em>Srinivasan Subramaniyan</em>, Rudra Joshi, Xiaorui Wang, and Marco Brocanelli </div> <div class="periodical"> <em>In Proceedings of the Tenth ACM/IEEE Symposium on Edge Computing</em>, the Hilton Arlington National Landing, Arlington, VA, USA, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1145/3769102.3772715" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/SEC.pdf" class="btn btn-sm z-depth-0" role="button" title="PDF">PDF</a> <a href="/assets/slides/SEC_2025_Presentation.pptx" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1145/3769102.3772715" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3769102.3772715</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Subramaniyan, Srinivasan and Joshi, Rudra and Wang, Xiaorui and Brocanelli, Marco}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SEEB-GPU: Early-Exit Aware Scheduling and Batching for Edge GPU Inference}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400722387}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3769102.3772715}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3769102.3772715}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Tenth ACM/IEEE Symposium on Edge Computing}</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{9}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{16}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{edge inference, GPU resource management, early-exit DNNs}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{the Hilton Arlington National Landing, Arlington, VA, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{SEC '25}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/fc.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="fc.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10.1145/3761812" class="col-sm-8"> <div class="title">FC-GPU: Feedback Control GPU Scheduling for Real-Time Embedded Systems</div> <div class="author"> <em>Srinivasan Subramaniyan</em> and Xiaorui Wang </div> <div class="periodical"> <em>ACM Transactions on Embedded Computing Systems</em>, Sep 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Outstanding Paper</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1145/3761812" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/3761812.pdf" class="btn btn-sm z-depth-0" role="button" title="PDF">PDF</a> <a href="https://github.com/srinivasans74?tab=repositories" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/slides/1-325-Subramaniyan-pres.pptx" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1145/3761812" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=luGswuwAAAAJ&amp;citation_for_view=luGswuwAAAAJ:WF5omc3nYNoC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Recieved the Outstanding Paper award for FC-GPU at ESWEEK 2025</p> </div> <div class="abstract hidden"> <p>GPUs have recently been adopted in many real-time embedded systems. However, existing GPU scheduling solutions are mostly open-loop and rely on the estimation of worst-case execution time (WCET). Although adaptive solutions, such as feedback control scheduling, have been previously proposed to handle this challenge for CPU-based real-time tasks, they cannot be directly applied to GPUs, because GPUs have different and more complex architectures and so schedulable utilization bounds cannot apply to GPUs yet. In this article, we propose FC-GPU, the first feedback control GPU scheduling framework for real-time embedded systems. To model the GPU resource contention among tasks, we analytically derive a multi-input–multi-output (MIMO) system model that captures the impacts of task rate adaptation on the response times of different tasks. Building on this model, we design a MIMO controller that dynamically adjusts task rates based on measured response times. Our extensive hardware testbed results on an NVIDIA RTX 3090 GPU and an AMD MI-100 GPU demonstrate that FC-GPU can provide better real-time performance even when the task execution times significantly increase at runtime.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10.1145/3761812</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Subramaniyan, Srinivasan and Wang, Xiaorui}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{FC-GPU: Feedback Control GPU Scheduling for Real-Time Embedded Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">issue_date</span> <span class="p">=</span> <span class="s">{September 2025}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{24}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{5s}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1539-9087}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3761812}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3761812}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ACM Transactions on Embedded Computing Systems}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{155}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{25}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{GPU scheduling, real-time systems, embedded systems, feedback control}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="10630927" class="col-sm-8"> <div class="title">Latency-Guaranteed Co-Location of Inference and Training for Reducing Data Center Expenses</div> <div class="author"> Guoyu Chen, <em>Srinivasan Subramaniyan</em>, and Xiaorui Wang </div> <div class="periodical"> <em>In 2024 IEEE 44th International Conference on Distributed Computing Systems (ICDCS)</em>, Sep 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1109/ICDCS60910.2024.00051" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/slides/icdcs24_v4.pptx" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/ICDCS60910.2024.00051" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=luGswuwAAAAJ&amp;citation_for_view=luGswuwAAAAJ:ufrVoPGSRksC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Today’s data centers often need to run various machine learning (ML) applications with stringent SLO (Service-Level Objective) requirements, such as inference latency. To that end, data centers prefer to 1) over-provision the number of servers used for inference processing and 2) isolate them from other servers that run ML training, despite both use GPUs extensively, to minimize possible competition of computing resources. Those practices result in a low GPU utilization and thus a high capital expense. Hence, if training and inference jobs can be safely co-located on the same GPUs with explicit SLO guarantees, data centers could flexibly run fewer training jobs when an inference burst arrives and run more afterwards to increase GPU utilization, reducing their capital expenses. In this paper, we propose GPUColo, a two-tier co-location solution that provides explicit ML inference SLO guarantees for co-located GPUs. In the outer tier, we exploit GPU spatial sharing to dynamically adjust the percentage of active GPU threads allocated to spatially co-located inference and training processes, so that the inference latency can be guaranteed. Because spatial sharing can introduce considerable overheads and thus cannot be conducted at a fine time granularity, we design an inner tier that puts training jobs into periodic sleep, so that the inference jobs can quickly get more GPU resources for more prompt latency control. Our hardware testbed results show that GPUColo can precisely control the inference latency to the desired SLO, while maximizing the throughput of the training jobs co-located on the same GPUs. Our large-scale simulation with a 57-day real-world data center trace (6500 GPUs) also demonstrates that GPU Colo enables latency-guaranteed inference and training co-location. Consequently, it allows 74.9 % of GPUs to be saved for a much lower capital expense.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10630927</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Guoyu and Subramaniyan, Srinivasan and Wang, Xiaorui}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2024 IEEE 44th International Conference on Distributed Computing Systems (ICDCS)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Latency-Guaranteed Co-Location of Inference and Training for Reducing Data Center Expenses}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/abstract/document/10630927}</span><span class="p">,</span>
  <span class="na">paper</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{473-484}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Training;Data centers;Graphics processing units;Machine learning;Throughput;Hardware;Servers;Machine learning;data center;inference;latency;GPU;co-location}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICDCS60910.2024.00051}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="10196662" class="col-sm-8"> <div class="title">OptiCPD: Optimization For The Canonical Polyadic Decomposition Algorithm on GPUs</div> <div class="author"> <em>Srinivasan Subramaniyan</em> and Xiaorui Wang </div> <div class="periodical"> <em>In 2023 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)</em>, Sep 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1109/IPDPSW59300.2023.00071" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/IPDPSW59300.2023.00071" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=luGswuwAAAAJ&amp;citation_for_view=luGswuwAAAAJ:Tyk-4Ss8FVUC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10196662</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Subramaniyan, Srinivasan and Wang, Xiaorui}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2023 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{OptiCPD: Optimization For The Canonical Polyadic Decomposition Algorithm on GPUs}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{403-412}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/10196662}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Tensors;Multicore processing;High performance computing;Optimal scheduling;Machine learning;Linear algebra;Parallel processing;CPD/PARAFAC;CPU;GPU;MTTKRP}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IPDPSW59300.2023.00071}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="9869892" class="col-sm-8"> <div class="title">Enabling High-Level Design Strategies for High-Throughput and Low-Power NB-LDPC Decoders</div> <div class="author"> <em>Srinivasan Subramaniyan</em>, Oscar Ferraz, M. R. Ashuthosh, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Santosh Krishna, Guohui Wang, Joseph R. Cavallaro, Vitor Silva, Gabriel Falcao, Madhura Purnaprajna' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </div> <div class="periodical"> <em>IEEE Design &amp; Test</em>, Sep 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1109/MDAT.2022.3202852" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/example_pdf.pdf" class="btn btn-sm z-depth-0" role="button" title="PDF">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/MDAT.2022.3202852" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=luGswuwAAAAJ&amp;citation_for_view=luGswuwAAAAJ:UeHWp8X0CEIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">9869892</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Subramaniyan, Srinivasan and Ferraz, Oscar and Ashuthosh, M. R. and Krishna, Santosh and Wang, Guohui and Cavallaro, Joseph R. and Silva, Vitor and Falcao, Gabriel and Purnaprajna, Madhura}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Design &amp; Test}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Enabling High-Level Design Strategies for High-Throughput and Low-Power NB-LDPC Decoders}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{40}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{85-95}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/document/9869892}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Decoding;Codes;Symbols;Parity check codes;Data processing;Graphics processing units;Sparse matrices;NB-LDPC;FPGA;GPU;RTL;HLS}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/MDAT.2022.3202852}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="9885949" class="col-sm-8"> <div class="title">MAPPARAT: A Resource Constrained FPGA-Based Accelerator for Sparse-Dense Matrix Multiplication</div> <div class="author"> M. R. Ashuthosh, Santosh Krishna, Vishvas Sudarshan, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Srinivasan Subramaniyan, Madhura Purnaprajna' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In 2022 35th International Conference on VLSI Design and 2022 21st International Conference on Embedded Systems (VLSID)</em>, Sep 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1109/VLSID2022.2022.00031" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/example_pdf.pdf" class="btn btn-sm z-depth-0" role="button" title="PDF">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/VLSID2022.2022.00031" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=luGswuwAAAAJ&amp;citation_for_view=luGswuwAAAAJ:eQOLeE2rZwMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Matrix Multiplication has gained importance due to its wide usage in Deep Neural Networks. The presence of sparsity in matrices needs special considerations to avoid redundancy in computations and memory accesses. Sparsity becomes relevant in the choice of compression format for storage and memory access. In addition to compression format, the choice of the algorithm also influences the performance of the matrix multiplier. The interplay of algorithm and compression formats results in significant variations in several performance parameters such as execution time, memory, and total energy consumed. This paper presents MAPPARAT, a custom FPGA-based hardware accelerator for sparse×dense matrix multiplication. Our analysis show that the choice of the compression format is heavily dependent on sparsity of the input matrices. We present two variants of MAPPARAT based on the algorithm used for sparse×dense matrix multiplication, viz., row-wise and column-wise product. A difference in speedup of 2.5× and a difference in energy consumption by about 2.6× is seen between the two variants. We show that an intelligent choice of algorithm and compression format based on the variations in sparsity, matrix dimensions, and device specifications is necessary for performance acceleration. For identical sparse matrices, a speedup of up to 3.6× is observed, when the dense format is chosen for one of the matrices for sparsity in the range of 30% to 90%. MAPPARAT on a resource-constrained device shows performance efficiency of up to 7 GOPs-per-second-per-watt.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">9885949</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ashuthosh, M. R. and Krishna, Santosh and Sudarshan, Vishvas and Subramaniyan, Srinivasan and Purnaprajna, Madhura}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2022 35th International Conference on VLSI Design and 2022 21st International Conference on Embedded Systems (VLSID)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{MAPPARAT: A Resource Constrained FPGA-Based Accelerator for Sparse-Dense Matrix Multiplication}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{102-107}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/document/9885949}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Performance evaluation;Deep learning;Energy consumption;Embedded systems;Redundancy;Neural networks;Very large scale integration}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/VLSID2022.2022.00031}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="ferraz2021survey" class="col-sm-8"> <div class="title">A survey on high-throughput non-binary LDPC decoders: ASIC, FPGA, and GPU architectures</div> <div class="author"> Oscar Ferraz, <em>Srinivasan Subramaniyan</em>, Ramesh Chinthala, and <span class="more-authors" title="click to view 7 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '7 more authors' ? 'João Andrade, Joseph R Cavallaro, Soumitra K Nandy, Vitor Silva, Xinmiao Zhang, Madhura Purnaprajna, Gabriel Falcao' : '7 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">7 more authors</span> </div> <div class="periodical"> <em>IEEE Communications Surveys &amp; Tutorials</em>, Sep 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1109/COMST.2021.3126127" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/example_pdf.pdf" class="btn btn-sm z-depth-0" role="button" title="PDF">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/COMST.2021.3126127" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=luGswuwAAAAJ&amp;citation_for_view=luGswuwAAAAJ:qjMakFHDy7sC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Non-binary low-density parity-check (NB-LDPC) codes show higher error-correcting performance than binary low-density parity-check (LDPC) codes when the codeword length is moderate and/or the channel has bursts of errors. The need for high-speed decoders for future digital communications led to the investigation of optimized NB-LDPC decoding algorithms and efficient implementations that target high throughput and low energy consumption levels. We carried out a comprehensive survey of existing NB-LDPC decoding hardware that targets the optimization of these parameters. Even though existing NB-LDPC decoders are optimized with respect to computational complexity and memory requirements, they still lag behind their binary counterparts in terms of throughput, power and area optimization. This study contributes to an overall understanding of the state-of-the-art on application-specific integrated-circuit (ASIC), field-programmable gate array (FPGA) and graphics processing units (GPU) based systems, and highlights the current challenges that still have to be overcome on the path to more efficient NB-LDPC decoder architectures.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ferraz2021survey</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A survey on high-throughput non-binary LDPC decoders: ASIC, FPGA, and GPU architectures}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ferraz, Oscar and Subramaniyan, Srinivasan and Chinthala, Ramesh and Andrade, Jo{\~a}o and Cavallaro, Joseph R and Nandy, Soumitra K and Silva, Vitor and Zhang, Xinmiao and Purnaprajna, Madhura and Falcao, Gabriel}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Communications Surveys \&amp; Tutorials}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/COMST.2021.3126127}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{24}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{524--556}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9606216}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="9195258" class="col-sm-8"> <div class="title">Pushing the Limits of Energy Efficiency for Non-Binary LDPC Decoders on GPUs and FPGAs</div> <div class="author"> <em>Srinivasan Subramaniyan</em>, Oscar Ferraz, M. R. Ashuthosh, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Santosh Krishna, Guohui Wang, Joseph R. Cavallaro, Vitor Silva, Gabriel Falcao, Madhura Purnaprajna' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </div> <div class="periodical"> <em>In 2020 IEEE Workshop on Signal Processing Systems (SiPS)</em>, Sep 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1109/SiPS50750.2020.9195258" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/example_pdf.pdf" class="btn btn-sm z-depth-0" role="button" title="PDF">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/SiPS50750.2020.9195258" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=luGswuwAAAAJ&amp;citation_for_view=luGswuwAAAAJ:9yKSN-GCB0IC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Signal processing hardware designers of Low-Density Parity-Check (LDPC) decoders used in modern optical communications are confronted with the need to perform multi-parametric design space exploration, targeting very high throughput (hundreds of Mbit/s) and low-power systems. This work addresses the needs of current designers of dedicated GF(2m) NB-LDPC decoders that necessitate robust approaches for dealing with the ever-increasing demand for higher BER performance. The constraints pose tremendous pressure on the on-chip design of irregular data structures and micro-circuit implementation for supporting the complex Galois field mathematics and communications of hundreds of check nodes with hundreds of variable node processors. We have developed kernels targeting GPU and FPGA (HLS and its equivalent RTL) descriptions of this class of complex circuits for comparing area, frequency of operation, latency, parallelism and throughput. Exploiting techniques such as using custom bit-widths, pipelining, loop-unrolling, array-partitioning and the replication of compute units, results in considerably faster design cycles and demands less non-recurring engineering effort. We report a throughput performance of 800 Mbps for the FPGA case.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">9195258</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Subramaniyan, Srinivasan and Ferraz, Oscar and Ashuthosh, M. R. and Krishna, Santosh and Wang, Guohui and Cavallaro, Joseph R. and Silva, Vitor and Falcao, Gabriel and Purnaprajna, Madhura}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2020 IEEE Workshop on Signal Processing Systems (SiPS)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Pushing the Limits of Energy Efficiency for Non-Binary LDPC Decoders on GPUs and FPGAs}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-6}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/document/9195258}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Field programmable gate arrays;Graphics processing units;Measurement;Kernel;Decoding;Instruction sets;Parity check codes;design space exploration;roofline model;high-throughput;parallelism;low-power;FPGAs;GPUs;RTL;HLS;NB-LDPC decoding}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/SiPS50750.2020.9195258}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="9114836" class="col-sm-8"> <div class="title">Gbit/s Non-Binary LDPC Decoders: High-Throughput using High-Level Specifications</div> <div class="author"> Oscar Ferraz, <em>Srinivasan Subramaniyan</em>, Guohui Wang, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Joseph R. Cavallaro, Gabriel Falcao, Madhura Purnaprajna' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In 2020 IEEE 28th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)</em>, Sep 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1109/FCCM48280.2020.00058" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/example_pdf.pdf" class="btn btn-sm z-depth-0" role="button" title="PDF">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/FCCM48280.2020.00058" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=luGswuwAAAAJ&amp;citation_for_view=luGswuwAAAAJ:d1gkVwhDpl0C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>It is commonly perceived that an HLS specification targeted for FPGAs cannot provide throughput performance in par with equivalent RTL descriptions. In this work we developed a complex design of a non-binary LDPC decoder, that although hard to generalise, shows that HLS provides sufficient architectural refinement options. They allow attaining performance above CPU- and GPU-based ones and excel at providing a faster design cycle when compared to RTL development.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">9114836</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ferraz, Oscar and Subramaniyan, Srinivasan and Wang, Guohui and Cavallaro, Joseph R. and Falcao, Gabriel and Purnaprajna, Madhura}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2020 IEEE 28th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Gbit/s Non-Binary LDPC Decoders: High-Throughput using High-Level Specifications}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{226-226}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/document/9114836}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Throughput;Parity check codes;Decoding;Field programmable gate arrays}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/FCCM48280.2020.00058}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="9074444" class="col-sm-8"> <div class="title">CoIn: Accelerated CNN Co-Inference through data partitioning on heterogeneous devices</div> <div class="author"> K. Vanishree, Anu George, Srivatsav Gunisetty, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Srinivasan Subramanian, Shravan Kashyap R., Madhura Purnaprajna' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In 2020 6th International Conference on Advanced Computing and Communication Systems (ICACCS)</em>, Sep 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1109/ICACCS48705.2020.9074444" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/example_pdf.pdf" class="btn btn-sm z-depth-0" role="button" title="PDF">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/ICACCS48705.2020.9074444" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=luGswuwAAAAJ&amp;citation_for_view=luGswuwAAAAJ:u5HHmVD_uO8C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>In Convolutional Neural Networks (CNN), the need for low inference time per batch is crucial for real-time applications. To improve the inference time, we present a method (CoIn) that benefits from the use of multiple devices that execute simultaneously. Our method achieves the goal of low inference time by partitioning images of a batch on diverse micro-architectures. The strategy for partitioning is based on offline profiling on the target devices. We have validated our partitioning technique on CPUs, GPUs and FPGAs that include memory-constrained devices in which case, a re-partitioning technique is applied. An average speedup of 1.39x and 1.5x is seen with CPU-GPU and CPU-GPU-FPGA co-execution respectively. In comparison with the approach of the state-of-the-art, CoIn has an average speedup of 1.62x across all networks.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">9074444</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Vanishree, K. and George, Anu and Gunisetty, Srivatsav and Subramanian, Srinivasan and Kashyap R., Shravan and Purnaprajna, Madhura}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2020 6th International Conference on Advanced Computing and Communication Systems (ICACCS)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{CoIn: Accelerated CNN Co-Inference through data partitioning on heterogeneous devices}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{90-95}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/abstract/document/9074444}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Performance evaluation;Graphics processing units;Field programmable gate arrays;Acceleration;Memory management;Time measurement;Computational modeling;CNN;CPU-GPU system;GPU-FPGA system;Data Partitioning;inference acceleration}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICACCS48705.2020.9074444}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Srinivasan Subramaniyan. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>